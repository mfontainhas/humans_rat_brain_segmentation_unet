import numpy as np
from keras.layers import BatchNormalization
from keras.models import *
from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Cropping3D, Dropout
from keras.optimizers import *
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras import backend as keras

class my2DUnet:
    def __init__(self, img_rows=64, img_cols=64, img_deep=1):
        self.img_rows = img_rows
        self.img_cols = img_cols
        self.img_deep = img_deep
        self.inputsize=(img_rows,img_cols,1)
        self.f=3
    @property
    def create_DL(self):
        inputs = Input(self.inputsize)
        f=self.f
        conv1 = Conv2D(64, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
        drop1 = Dropout(0.2)(conv1)
        conv11 = Conv2D(64, (f,f),  activation='relu', padding='same', kernel_initializer='he_normal')(drop1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)
        batch1=BatchNormalization()(pool1)
        drop11 = Dropout(0.2)(batch1)
        conv2 = Conv2D(128, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop11)
        drop2 = Dropout(0.2)(conv2)
        conv22 = Conv2D(128,(f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)
        batch2=BatchNormalization()(pool2)
        drop22 = Dropout(0.2)(batch2)
        conv3 = Conv2D(256,(f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop22)
        drop3 = Dropout(0.2)(conv3)
        conv33 = Conv2D(256, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)
        batch3=BatchNormalization()(pool3)
        drop33 = Dropout(0.2)(batch3)
        conv4 = Conv2D(512, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop33)
        drop4 = Dropout(0.2)(conv4)
        conv44 = Conv2D(512,(f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(conv44)
        batch4=BatchNormalization()(pool4)
        drop44 = Dropout(0.3)(batch4)
        conv5 = Conv2D(1024, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop44)
        drop5 = Dropout(0.2)(conv5)
        conv55 = Conv2D(1024, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop5)
        batch5=BatchNormalization()(conv55)
        drop55 = Dropout(0.2)(batch5)
        up6 = Conv2D(512, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop55))
        merge6 = concatenate([conv44, up6], axis=3)
        batch6=BatchNormalization()(merge6)
        drop6 = Dropout(0.3)(batch6)
        conv6 = Conv2D(512,(f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop6)
        drop66 = Dropout(0.2)(conv6)
        conv66 = Conv2D(512,(f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop66)
        up7 = Conv2D(256, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv66))
        merge7 = concatenate([conv33 , up7], axis=3)
        batch7=BatchNormalization()(merge7)
        drop7 = Dropout(0.2)(batch7)
        conv7 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop7)
        drop77 = Dropout(0.2)(conv7)
        conv77 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop77)
        up8 = Conv2D(128,( 2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv77))
        merge8 = concatenate([conv22, up8], axis=3)
        batch8=BatchNormalization()(merge8)
        drop8 = Dropout(0.3)(batch8)
        conv8 = Conv2D(128, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop8)
        drop88 = Dropout(0.2)(conv8)
        conv88 = Conv2D(128, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop88)
        up9 = Conv2D(64,(2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv88))
        merge9 = concatenate([conv11, up9], axis=3)
        batch9=BatchNormalization()(merge9)
        drop9 = Dropout(0.3)(batch9)
        conv9 = Conv2D(64, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop9)
        drop99 = Dropout(0.5)(conv9)
        conv99 = Conv2D(64, (f,f), activation='relu', padding='same', kernel_initializer='he_normal')(drop99)
        #conv999 = Conv2D(2, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv99)
        conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv99)
        model = Model(input=inputs, output=conv10)
        print(model.summary())
        #model.load_weights('/Notebooks/Marianadissertation/Rats/pythonrats2D/bestvalueslasttrain/S5 (sem imagens para teste)/bestweights_vall_loss.hdf5', by_name=True)


        return model

'''
    def create_DL(self):
        inputs = Input(self.inputsize)
        conv1 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
        drop1 = Dropout(0.2)(conv1)
        conv11 = Conv2D(64, (3,3),  activation='relu', padding='same', kernel_initializer='he_normal')(drop1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)
        batch1=BatchNormalization()(pool1)
        drop11 = Dropout(0.2)(batch1)
        conv2 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop11)
        drop2 = Dropout(0.2)(conv2)
        conv22 = Conv2D(128,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)
        batch2=BatchNormalization()(pool2)
        drop22 = Dropout(0.2)(batch2)
        conv3 = Conv2D(256,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop22)
        drop3 = Dropout(0.2)(conv3)
        conv33 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)
        batch3=BatchNormalization()(pool3)
        drop33 = Dropout(0.2)(batch3)
        conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop33)
        drop4 = Dropout(0.2)(conv4)
        conv44 = Conv2D(512,(3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(conv44)
        batch4=BatchNormalization()(pool4)
        drop44 = Dropout(0.3)(batch4)
        conv5 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop44)
        drop5 = Dropout(0.2)(conv5)
        conv55 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop5)
        batch5=BatchNormalization()(conv55)
        drop55 = Dropout(0.2)(batch5)
        up6 = Conv2D(512, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop55))
        merge6 = concatenate([conv44, up6], axis=3)
        batch6=BatchNormalization()(merge6)
        drop6 = Dropout(0.3)(batch6)
        conv6 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop6)
        drop66 = Dropout(0.2)(conv6)
        conv66 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop66)
        up7 = Conv2D(256, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv66))
        merge7 = concatenate([conv33 , up7], axis=3)
        batch7=BatchNormalization()(merge7)
        drop7 = Dropout(0.2)(batch7)
        conv7 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop7)
        drop77 = Dropout(0.2)(conv7)
        conv77 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop77)
        up8 = Conv2D(128,( 2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv77))
        merge8 = concatenate([conv22, up8], axis=3)
        batch8=BatchNormalization()(merge8)
        drop8 = Dropout(0.3)(batch8)
        conv8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop8)
        drop88 = Dropout(0.2)(conv8)
        conv88 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop88)
        up9 = Conv2D(64,(2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv88))
        merge9 = concatenate([conv11, up9], axis=3)
        batch9=BatchNormalization()(merge9)
        drop9 = Dropout(0.3)(batch9)
        conv9 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop9)
        drop99 = Dropout(0.5)(conv9)
        conv99 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop99)
        #conv999 = Conv2D(2, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv99)
        conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv99)
        model = Model(input=inputs, output=conv10)
        model.load_weights('/Notebooks/Marianadissertation/Rats/pythonrats2D/bestvalueslasttrain/S1/bestweights_vall_loss.hdf5', by_name=True)

        return model
    def create_DL_S4(self):
        inputs = Input(self.inputsize)
        conv1 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
        conv11 = Conv2D(64, (3,3),  activation='relu', padding='same', kernel_initializer='he_normal')(conv1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)
        batch1=BatchNormalization()(pool1)
        drop1 = Dropout(0.2)(batch1)
        conv2 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop1)
        conv22 = Conv2D(128,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)
        batch2=BatchNormalization()(pool2)
        drop2 = Dropout(0.2)(batch2)
        conv3 = Conv2D(256,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop2)
        conv33 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)
        batch3=BatchNormalization()(pool3)
        drop3 = Dropout(0.2)(batch3)
        conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop3)
        conv44 = Conv2D(512,(3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(conv44)
        batch4=BatchNormalization()(pool4)
        drop4 = Dropout(0.2)(batch4)
        conv5 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop4)
        conv55 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv5)
        batch5=BatchNormalization()(conv55)
        drop5 = Dropout(0.2)(batch5)
        up6 = Conv2D(512, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))
        merge6 = concatenate([conv44, up6], axis=3)
        batch6=BatchNormalization()(merge6)
        drop6 = Dropout(0.2)(batch6)
        conv6 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop6)
        conv66 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv6)
        up7 = Conv2D(256, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv66))
        merge7 = concatenate([conv33 , up7], axis=3)
        batch7=BatchNormalization()(merge7)
        drop7 = Dropout(0.2)(batch7)
        conv7 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop7)
        conv77 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv7)
        up8 = Conv2D(128,( 2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv77))
        merge8 = concatenate([conv22, up8], axis=3)
        batch8=BatchNormalization()(merge8)
        drop8 = Dropout(0.2)(batch8)
        conv8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop8)
        conv88 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv8)
        up9 = Conv2D(64,(2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv88))
        merge9 = concatenate([conv11, up9], axis=3)
        batch9=BatchNormalization()(merge9)
        drop9 = Dropout(0.2)(batch9)
        conv9 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop9)
        drop99 = Dropout(0.5)(conv9)
        conv99 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop99)
        #conv999 = Conv2D(2, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv99)
        conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv99)
        model = Model(input=inputs, output=conv10)
        #model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])
        model.load_weights('/Notebooks/Marianadissertation/Rats/pythonrats2D/bestvalueslasttrain/S1/bestweights_vall_loss.hdf5', by_name=True)

        return model
        
class my2DUnet_S3:
    def __init__(self, img_rows=64, img_cols=64, img_deep=1):
        self.img_rows = img_rows
        self.img_cols = img_cols
        self.img_deep = img_deep
        self.inputsize=(img_rows,img_cols,1)
    @property
    def create_DL(self):
        inputs = Input(self.inputsize)
        conv1 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
        conv11 = Conv2D(64, (3,3),  activation='relu', padding='same', kernel_initializer='he_normal')(conv1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)
        batch1=BatchNormalization()(pool1)
        drop1 = Dropout(0.1)(batch1)
        conv2 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop1)
        conv22 = Conv2D(128,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)
        batch2=BatchNormalization()(pool2)
        drop2 = Dropout(0.1)(batch2)
        conv3 = Conv2D(256,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop2)
        conv33 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)
        batch3=BatchNormalization()(pool3)
        drop3 = Dropout(0.1)(batch3)
        conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop3)
        conv44 = Conv2D(512,(3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(conv44)
        batch4=BatchNormalization()(pool4)
        drop4 = Dropout(0.1)(batch4)
        conv5 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop4)
        conv55 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv5)
        batch5=BatchNormalization()(conv55)
        drop5 = Dropout(0.1)(batch5)
        up6 = Conv2D(512, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))
        merge6 = concatenate([conv44, up6], axis=3)
        batch6=BatchNormalization()(merge6)
        drop6 = Dropout(0.1)(batch6)
        conv6 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop6)
        conv66 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv6)
        up7 = Conv2D(256, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv66))
        merge7 = concatenate([conv33 , up7], axis=3)
        batch7=BatchNormalization()(merge7)
        drop7 = Dropout(0.1)(batch7)
        conv7 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop7)
        conv77 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv7)
        up8 = Conv2D(128,( 2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv77))
        merge8 = concatenate([conv22, up8], axis=3)
        batch8=BatchNormalization()(merge8)
        drop8 = Dropout(0.1)(batch8)
        conv8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(drop8)
        conv88 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv8)
        up9 = Conv2D(64,(2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv88))
        merge9 = concatenate([conv11, up9], axis=3)
        batch9=BatchNormalization()(merge9)
        drop9 = Dropout(0.1)(batch9)
        conv9 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop9)
        drop99 = Dropout(0.1)(conv9)
        conv99 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(drop99)
        conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv99)
        model = Model(input=inputs, output=conv10)
        #model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])
        model.load_weights('/Notebooks/Marianadissertation/Rats/pythonrats2D/bestvalueslasttrain/S1/bestweights_vall_loss.hdf5', by_name=True)

        return model
    @property
    def create_DL_S2(self):
        inputs = Input(self.inputsize)
        conv1 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
        conv11 = Conv2D(64, (3,3),  activation='relu', padding='same', kernel_initializer='he_normal')(conv1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)
        batch1=BatchNormalization()(pool1)
        #drop1 = Dropout(0.1)(batch1)
        conv2 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(batch1)
        conv22 = Conv2D(128,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)
        batch2=BatchNormalization()(pool2)
        #drop2 = Dropout(0.1)(batch2)
        conv3 = Conv2D(256,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(batch2)
        conv33 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)
        #drop3 = Dropout(0.1)(pool3)
        batch3=BatchNormalization()(pool3)
        conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(batch3)
        conv44 = Conv2D(512,(3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(conv44)
        batch4=BatchNormalization()(pool4)
        #drop4 = Dropout(0.1)(batch4)
        conv5 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(batch4)
        conv55 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv5)
        #drop5 = Dropout(0.1)(conv55)
        up6 = Conv2D(512, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv55))
        merge6 = concatenate([conv44, up6], axis=3)
        batch6=BatchNormalization()(merge6)
        #drop6 = Dropout(0.1)(batch6)
        conv6 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(batch6)
        conv66 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv6)
        up7 = Conv2D(256, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv66))
        merge7 = concatenate([conv33 , up7], axis=3)
        batch7=BatchNormalization()(merge7)
        #drop7 = Dropout(0.1)(batch7)
        conv7 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(batch7)
        conv77 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv7)
        up8 = Conv2D(128,( 2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv77))
        merge8 = concatenate([conv22, up8], axis=3)
        batch8=BatchNormalization()(merge8)
        #drop8 = Dropout(0.1)(batch8)
        conv8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(batch8)
        conv88 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv8)
        up9 = Conv2D(64,(2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv88))
        merge9 = concatenate([conv11, up9], axis=3)
        batch9=BatchNormalization()(merge9)
        #drop9 = Dropout(0.1)(batch9)
        conv9 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(batch9)
        drop9 = Dropout(0.1)(conv9)
        conv99 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(9)
        conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv99)
        model = Model(input=inputs, output=conv10)
        #model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])
        model.load_weights('/Notebooks/Marianadissertation/Rats/pythonrats2D/bestvalueslasttrain/S1/bestweights_vall_loss.hdf5', by_name=True)

        return model

 def create_DL_S1(self):
        inputs = Input(self.inputsize)
        conv1 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
        conv11 = Conv2D(64, (3,3),  activation='relu', padding='same', kernel_initializer='he_normal')(conv1)
        pool1 = MaxPooling2D(pool_size=(2, 2))(conv11)
        #batch1=BatchNormalization()(pool1)
        #drop1 = Dropout(0.1)(batch1)
        conv2 = Conv2D(128, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(pool1)
        conv22 = Conv2D(128,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv2)
        pool2 = MaxPooling2D(pool_size=(2, 2))(conv22)
        #batch2=BatchNormalization()(pool2)
        #drop2 = Dropout(0.1)(batch2)
        conv3 = Conv2D(256,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(pool2)
        conv33 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv3)
        pool3 = MaxPooling2D(pool_size=(2, 2))(conv33)
        #drop3 = Dropout(0.1)(pool3)
        #batch3=BatchNormalization()(pool3)
        conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(pool3)
        conv44 = Conv2D(512,(3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv4)
        pool4 = MaxPooling2D(pool_size=(2, 2))(conv44)
        #batch4=BatchNormalization()(pool4)
        #drop4 = Dropout(0.1)(batch4)
        conv5 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(pool4)
        conv55 = Conv2D(1024, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv5)
        #drop5 = Dropout(0.1)(conv55)
        up6 = Conv2D(512, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv55))
        merge6 = concatenate([conv44, up6], axis=3)
        #batch6=BatchNormalization()(merge6)
        #drop6 = Dropout(0.1)(batch6)
        conv6 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(merge6)
        conv66 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv6)
        up7 = Conv2D(256, (2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv66))
        merge7 = concatenate([conv33 , up7], axis=3)
        #batch7=BatchNormalization()(merge7)
        #drop7 = Dropout(0.1)(batch7)
        conv7 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(merge7)
        conv77 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv7)
        up8 = Conv2D(128,( 2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv77))
        merge8 = concatenate([conv22, up8], axis=3)
        #batch8=BatchNormalization()(merge8)
        #drop8 = Dropout(0.1)(batch8)
        conv8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(merge8)
        conv88 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(conv8)
        up9 = Conv2D(64,(2,2), activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv88))
        merge9 = concatenate([conv11, up9], axis=3)
        #batch9=BatchNormalization()(merge9)
        #drop9 = Dropout(0.1)(batch9)
        conv9 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(merge9)
        #drop9 = Dropout(0.1)(conv9)
        conv99 = Conv2D(64, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv9)
        conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv99)
        model = Model(input=inputs, output=conv10)
        #model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])


        return model


'''